# Part 1: Architecture Design - Service Analysis & Infrastructure Selection

**Document Version**: 1.0  
**Last Updated**: January 29, 2026  
**Audience**: DevOps Engineers, Solution Architects, Technical Decision Makers

---

## üìã Executive Summary

This document outlines the AWS infrastructure recommendations for the AI Chatbot Framework, analyzing each application component and justifying infrastructure choices.

### Final Architecture Decisions

| Layer | Service | Reasoning |
|-------|---------|-----------|
| **Compute** | Amazon EKS | Long-running stateful APIs with ML workloads |
| **Database** | MongoDB Atlas | Document-based, schema-flexible, already integrated |
| **Caching** | ElastiCache Redis | Session storage, conversation context, fast access |
| **Messaging** | Amazon SQS | Async background jobs, decoupling |
| **Storage** | Amazon S3 | Static assets, logs, ML artifacts, infrastructure state |

---

## üéØ Part 1: Compute Infrastructure Analysis

### Application Component: Backend Service

**Characteristics:**
- NLU (Natural Language Understanding) processing
- ML inference (heavy CPU/memory)
- REST APIs (FastAPI)
- Long-running requests (some queries take 2-5 seconds)
- Stateful conversation management
- Needs isolation and independent scaling

**Key Requirements:**
- Handle variable load (peak during business hours)
- Support multiple concurrent conversations
- Fine-grained resource allocation
- Easy integration with ML models

---

## üîç Option 1: AWS Lambda - ‚ùå **NOT Suitable**

### What is Lambda?

AWS Lambda is a serverless compute service where you upload code and AWS runs it in response to events.
```
User Request
    ‚Üì
Lambda triggered
    ‚Üì
Function executes (up to 15 minutes)
    ‚Üì
Lambda stops
    ‚Üì
Response sent
```

### Why Lambda Works Well For:

‚úÖ Short-duration requests (< 1 minute)  
‚úÖ Event-driven processing (file uploads, database changes)  
‚úÖ Spiky traffic patterns (long idle periods)  
‚úÖ Small, focused functions  
‚úÖ Minimal operational overhead  

**Example use case:** Processing uploaded documents ‚Üí Lambda is perfect

### Problems for AI Chatbot Backend:

‚ùå **Cold Start Delays**
- Lambda function startup: 3-10 seconds
- For chat responses, this is unacceptable
- Users expect < 1 second response times

‚ùå **15-Minute Execution Limit**
- ML model inference can be slow
- Complex conversations might approach limits
- Retraining jobs definitely exceed 15 minutes

‚ùå **WebSocket/Streaming Limitations**
- Lambda doesn't support persistent connections
- Chat platforms need bidirectional real-time updates
- Lambda is request-response only

‚ùå **Stateful Memory Management**
- Each Lambda invocation is isolated
- Conversation context must be re-loaded from database each time
- No persistent in-memory caching between requests

‚ùå **Cost at Scale**
- High-frequency chat API would incur per-request charges
- 1,000 requests/hour √ó 30 days = 720,000 invocations
- At $0.20 per 1M invocations, cost adds up quickly
- Fixed EKS cluster is cheaper for predictable load

### Cost Comparison: Lambda vs EKS for Chatbot

**Lambda Scenario:**
- 100 requests/minute = 144,000/day
- Average execution: 3 seconds = 432,000 GB-seconds/day
- Cost: ~$17.28/day or ~$518/month

**EKS Scenario:**
- EKS control plane: ~$73/month
- 2-4 t3.medium nodes: ~$200-400/month
- Total: ~$273-473/month

**Verdict: EKS is cheaper at scale + better performance**

### Verdict: ‚ùå Lambda is NOT suitable for this backend

---

## üîç Option 2: AWS App Runner - ‚ö†Ô∏è **Limited Fit**

### What is App Runner?

AWS App Runner is a fully managed container service - simpler than EKS but less flexible.
```
You push Docker image ‚Üí App Runner manages containers ‚Üí Auto-scales
```

### Why App Runner Works Well For:

‚úÖ Simple containerized web apps  
‚úÖ No Kubernetes expertise required  
‚úÖ Automatic scaling  
‚úÖ Minimal operational overhead  
‚úÖ Good for proof-of-concepts  

**Example use case:** Hosting a simple web API with predictable load

### Problems for AI Chatbot Backend:

‚ùå **Limited Scaling Control**
- Can't specify exact resource limits per request
- ML workloads need fine-grained CPU allocation
- No pod-level resource guarantees

‚ùå **No Native GitOps**
- App Runner doesn't integrate with ArgoCD
- Manual deployments required
- Harder to manage multiple environments

‚ùå **Restricted Observability**
- Limited CloudWatch integration
- Can't instrument individual containers
- ML model performance tracking is difficult

‚ùå **No Multi-Node Deployment**
- Scales horizontally but less transparent
- Can't separate general vs ML workloads

### Verdict: ‚ö†Ô∏è App Runner is good for PoC, not production ML workloads

---

## üîç Option 3: Amazon ECS on EC2 - ‚úÖ **Valid Alternative**

### What is ECS on EC2?

You manage EC2 instances, ECS orchestrates containers on those instances.
```
You provision EC2 instances
    ‚Üì
ECS launches Docker containers on them
    ‚Üì
You manage instance lifecycle (scaling, patching)
```

### Why ECS EC2 Works Well For:

‚úÖ Better cost efficiency than ECS Fargate  
‚úÖ More control than App Runner  
‚úÖ Simpler than Kubernetes  
‚úÖ Native AWS service (tight CloudWatch integration)  
‚úÖ Good for steady, predictable workloads  

### Advantages Over ECS Fargate:

- Lower cost (you manage compute)
- More control over instance selection
- Better for right-sizing workloads

### Problems for AI Chatbot Backend:

‚ùå **Less Granular Scaling**
- Scales by EC2 instances, not individual containers
- If you have 1 instance, you can't scale below it

‚ùå **ML & API Sharing Compute**
- Can't easily isolate ML workloads
- One heavy model can impact API responses

‚ùå **No Native Helm Support**
- Must write ECS task definitions (different from industry standard)
- Harder to share configurations across teams

‚ùå **Slower Scaling**
- Launching EC2 instance takes 2-5 minutes
- Kubernetes node scaling is faster

‚ùå **More Operational Work**
- Must manage EC2 patching
- Must monitor EC2 health
- Must handle instance failures

### Cost Comparison: ECS EC2 vs EKS

**ECS EC2:**
- 2 x t3.medium: ~$30/month
- Data transfer: variable
- Simple but more ops work

**EKS:**
- Control plane: $73/month
- 2 x t3.medium: ~$30/month
- Total: ~$103/month
- Better orchestration, GitOps, industry standard

**For 1-2 applications, ECS EC2 is slightly cheaper**  
**For 3+ applications, EKS becomes better ROI**

### Verdict: ‚úÖ Valid production option, but more operational overhead than EKS

---

## üîç Option 4: Amazon EKS (Kubernetes) - ‚úÖ **CHOSEN**

### What is EKS?

Amazon Elastic Kubernetes Service is a fully managed Kubernetes cluster.
```
AWS manages:
- Control plane (API server, scheduler, etcd)
- Patching and upgrades
- High availability

You manage:
- Worker nodes
- Application deployments
- Helm charts
```

### Why EKS Works Well For AI Chatbot:

‚úÖ **Designed for Complex Workloads**
- Backend + ML inference + caching all on same cluster
- Each can have different resource requirements

‚úÖ **Industry Standard**
- Kubernetes is standard in production environments
- Skills transfer to other companies
- Huge ecosystem of tools

‚úÖ **Fine-Grained Autoscaling**
- Horizontal Pod Autoscaler (HPA): Scales pods based on CPU/memory
- Cluster Autoscaler: Scales nodes automatically
- Can scale from 2 to 10 nodes in 30 seconds

‚úÖ **Environment Isolation**
- Different namespaces for dev/staging/prod
- Different node groups for different workload types
- Network policies for pod-to-pod communication

‚úÖ **Native Helm Integration**
- Frontend, backend, database all deployed with Helm
- Templating for dev/staging/prod configurations
- Industry standard package management

‚úÖ **Perfect GitOps Match**
- ArgoCD watches git repo
- Automatic deployments on code changes
- Declarative infrastructure
- Easy rollbacks

‚úÖ **Observability Built-In**
- Prometheus metrics available
- Container logs in CloudWatch
- Distributed tracing possible
- Deep visibility into pod behavior

### EKS Architecture for This Project
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         EKS Cluster (Managed)           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ  General NG  ‚îÇ   ML Node    ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ (t3.medium)  ‚îÇ  (c5.xlarge) ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ   2-5 nodes  ‚îÇ   1-3 nodes  ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ         ‚îÇ              ‚îÇ               ‚îÇ
‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ    ‚îÇ  Backend  ‚îÇ  ‚îÇ   ML Pod  ‚îÇ      ‚îÇ
‚îÇ    ‚îÇ  Frontend ‚îÇ  ‚îÇ Inference ‚îÇ      ‚îÇ
‚îÇ    ‚îÇ MongoDB   ‚îÇ  ‚îÇ           ‚îÇ      ‚îÇ
‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Scaling Strategy

**Horizontal Pod Autoscaling (HPA)**
```
Backend pods:
- Min: 2 replicas
- Max: 10 replicas
- Scale at: 70% CPU utilization
- Scales in 30-60 seconds
```

**Vertical Pod Autoscaling (VPA)**
```
Optional: Recommends right-sized resource limits
Helps optimize cost
```

**Cluster Autoscaling**
```
Worker nodes:
- General workloads: 2-5 t3.medium nodes
- ML workloads: 1-3 c5.xlarge nodes
- Auto-adds nodes when needed
- Auto-removes idle nodes
```

### Cost Analysis: EKS

**Fixed Costs:**
- EKS control plane: $73/month

**Compute Costs (2-4 t3.medium nodes at normal traffic):**
- Dev: 1 node @ $30/month
- Staging: 2 nodes @ $60/month
- Prod: 3 nodes @ $90/month

**Total: ~$253/month for 3 environments**

**Scaling Benefit:**
- At peak: 4-6 nodes
- At off-peak: 1-2 nodes per environment
- Average cost: ~$150-200/month
- Much cheaper than fixed-size ECS or Lambda

### Verdict: ‚úÖ **EKS is BEST for this project**

**Reasoning Summary:**
- Supports long-running stateful APIs ‚úì
- Supports ML inference isolation ‚úì
- Scales efficiently from 1-100+ requests/sec ‚úì
- Native Helm support ‚úì
- Perfect ArgoCD integration ‚úì
- Cost-effective at scale ‚úì
- Industry standard ‚úì

---

## üíæ Part 2: Database Infrastructure Analysis

### Application Component: Data Storage

**Data Types:**
- Conversations (growing, historical)
- Session memory (temporary, TTL-based)
- Bot configurations (reference data)
- Training intents/entities (evolving schema)

**Key Requirements:**
- Flexible schema (intents/entities change)
- Fast document queries
- TTL-based expiration
- High availability and backups
- No complex joins

---

## üîç Option 1: Amazon RDS (MySQL/PostgreSQL) - ‚ùå **NOT Suitable**

### What is RDS?

Managed relational database with fixed schema (tables, columns, rows).

### Why RDS Works Well For:

‚úÖ Financial transactions  
‚úÖ Clear relational structure (orders ‚Üí items ‚Üí payments)  
‚úÖ Strong ACID guarantees  
‚úÖ Complex reporting with JOINs  

### Problems for Chatbot Data:

‚ùå **Inflexible Schema**
```sql
-- Example: RDS requires predefined structure
CREATE TABLE conversations (
  id INT,
  user_id INT,
  message TEXT,
  intent VARCHAR(50),
  entities JSON  -- JSON is secondary, not native
);

-- Adding new fields requires ALTER TABLE
-- Intents might change: {"type": "order_status"} ‚Üí {"type": "order_status", "priority": "high"}
-- Each schema change locks the table temporarily
```

‚ùå **Schema Migration Pain**
- Adding a new intent type requires migration
- Downtime or careful coordination required
- Not ideal for rapidly evolving NLU systems

‚ùå **Poor Fit for Document Data**
- Conversations are hierarchical (user ‚Üí messages ‚Üí intents)
- Fitting into relational tables is awkward
- Requires multiple JOINs to reconstruct

‚ùå **Limited Horizontal Scaling**
- Reads can scale with read replicas
- Writes must go to single master
- At 1,000 concurrent users, single writer becomes bottleneck

### Cost Comparison: RDS vs MongoDB

**RDS (db.t3.medium):**
- ~$60/month

**MongoDB Atlas (M10 cluster):**
- ~$57/month

**Cost is similar, but MongoDB is better fit**

### Verdict: ‚ùå RDS is wrong model for chatbot data

---

## üîç Option 2: Amazon DynamoDB - ‚ö†Ô∏è **Possible but Suboptimal**

### What is DynamoDB?

AWS-native NoSQL key-value store, serverless and infinitely scalable.

### Why DynamoDB Works Well For:

‚úÖ Simple key lookups  
‚úÖ Massive scale (millions of requests/sec)  
‚úÖ No servers to manage  
‚úÖ Pay-per-request pricing  

### Problems for Chatbot Data:

‚ùå **Complex Querying Difficult**
```python
# With MongoDB, easy:
db.conversations.find({"user_id": 123, "timestamp": {"$gt": yesterday}})

# With DynamoDB, complex:
# - Requires DynamoDB Query or Scan
# - Scan is slow and expensive on large tables
# - Secondary indexes add complexity
```

‚ùå **Changing Access Patterns**
- Today: "Find conversations by user"
- Tomorrow: "Find conversations by bot_id"
- Each new pattern might require new index

‚ùå **Code Rewrite Required**
- Project already uses MongoDB drivers
- Switching to DynamoDB requires code changes
- Risk of bugs during migration

‚ùå **JSON-like Data is Awkward**
```python
# DynamoDB item example
{
  "user_id": "123",  # Must be String in DynamoDB
  "conversation": {
    "messages": [  # Complex nested structures are stored as strings
      {"text": "...", "intent": "..."}
    ]
  }
}

# MongoDB handles this natively with rich types
```

### Cost Analysis: DynamoDB

**On-Demand Pricing:**
- Read: $1.25 per 1M reads
- Write: $6.25 per 1M writes

**For 1,000 conversations/day, each with 5 reads + 1 write:**
- Reads: 5,000/day = 150,000/month = $0.19/month
- Writes: 1,000/day = 30,000/month = $0.19/month
- Total: ~$0.38/month (very cheap!)

**Provisioned Capacity:**
- 100 RCUs + 50 WCUs = ~$50/month
- Better for predictable workloads

**Verdict: DynamoDB is cheaper, but requires code changes**

### Verdict: ‚ö†Ô∏è **Technically possible, but requires major refactoring**

---

## üîç Option 3: MongoDB Atlas - ‚úÖ **CHOSEN**

### What is MongoDB Atlas?

Fully managed MongoDB in the cloud. Document database with flexible schema.

### Why MongoDB is Perfect for This Project:

‚úÖ **Already Integrated**
- Project uses PyMongo (Python MongoDB driver)
- Zero code changes required
- Immediate deployment

‚úÖ **Natural Document Model**
```python
# MongoDB stores documents natively
conversation = {
    "user_id": "123",
    "messages": [
        {
            "text": "What's my order status?",
            "intent": "order_status",
            "confidence": 0.95,
            "entities": {"order_id": "456"}
        },
        {
            "text": "Your order 456 is shipped",
            "type": "bot_response"
        }
    ],
    "created_at": datetime.now(),
    "session_data": {
        "context": {...},
        "memory": {...}
    }
}

# Store directly - no schema mapping needed
db.conversations.insert_one(conversation)
```

‚úÖ **Schema Flexibility**
- Intents can evolve without migrations
- New fields added on-the-fly
- Different conversations can have different structures

‚úÖ **Powerful Queries**
```python
# Find conversations by user, sorted by recency
conversations = db.conversations.find(
    {"user_id": user_id}
).sort("created_at", -1).limit(10)

# Find by intent type (across nested documents)
intent_stats = db.conversations.aggregate([
    {"$unwind": "$messages"},
    {"$match": {"messages.intent": "order_status"}},
    {"$group": {"_id": "$user_id", "count": {"$sum": 1}}}
])
```

‚úÖ **High Availability**
- Automatic replication across 3 zones
- Automatic failover
- Point-in-time backup

‚úÖ **Scalability**
- Vertical: Bigger instance size
- Horizontal: Sharding (if needed)
- MongoDB Atlas handles ops

### MongoDB Atlas Pricing

**M10 Cluster (Dev/Staging):**
- 2GB storage
- $57/month
- Suitable for 10,000+ conversations

**M20 Cluster (Production):**
- 20GB storage
- $213/month
- Suitable for 100,000+ conversations

**Total for 3 environments: ~$285/month**

### Comparison with DocumentDB

AWS DocumentDB is MongoDB-compatible alternative:
- More expensive per month (~$100+)
- Still requires setup and maintenance
- MongoDB Atlas is fully managed with better pricing

### Verdict: ‚úÖ **MongoDB Atlas is PERFECT choice**

**Reasons:**
- Zero code changes ‚úì
- Natural document model ‚úì
- Fully managed operations ‚úì
- Flexible schema ‚úì
- Proven reliability ‚úì
- Cost-effective ‚úì

---

## ‚ö° Part 3: Caching Strategy

### Problem: Why Cache at All?

Without caching, every request hits the database and recomputes intents:
```
User sends message
    ‚Üì
Backend receives request
    ‚Üì
Query DB for bot config (200ms)
    ‚Üì
Query DB for user session (150ms)
    ‚Üì
Run NLU processing (500ms)
    ‚Üì
Total: 850ms before response
    ‚Üì
User sees delay
```

With caching:
```
User sends message
    ‚Üì
Check Redis for bot config (2ms) ‚Üê HIT
    ‚Üì
Check Redis for user session (2ms) ‚Üê HIT
    ‚Üì
Run NLU processing (500ms)
    ‚Üì
Total: 504ms - 340ms improvement!
```

---

## üîç Option 1: ElastiCache Redis - ‚úÖ **CHOSEN**

### What is Redis?

In-memory key-value store with advanced data structures.

### Why Redis for Chatbot:

‚úÖ **Extremely Low Latency**
- 1-2ms response time vs 200ms+ database

‚úÖ **Shared Cache**
- All 5 backend pods access same cache
- Conversation context shared across replicas

‚úÖ **TTL Support**
```python
# Session expires after 1 hour
cache.setex("session:user123", 3600, session_data)
```

‚úÖ **Advanced Structures**
- Lists: Recent intents
- Sets: User interactions
- Sorted sets: Leaderboards
- Hashes: Bot configurations

### Use Cases in Chatbot:
```python
# 1. Conversation Context
cache.set(f"context:user_{user_id}", context_data, ex=3600)

# 2. Bot Configurations
cache.set("bot_config:default", config_json, ex=86400)

# 3. User Session State
cache.hset(f"session:{session_id}", mapping=session_state)

# 4. Rate Limiting
cache.incr(f"ratelimit:{user_id}:requests")

# 5. Frequently Accessed Intents
cache.zadd("popular_intents", {"order_status": 100, "faq": 50})
```

### Redis Pricing

**cache.t4g.micro (dev):**
- 0.5GB
- $11/month

**cache.t4g.small (staging):**
- 1.37GB
- $18/month

**cache.r7g.large (prod):**
- 15.5GB
- $100/month

**Total: ~$130/month for 3 environments**

### High Availability Options

**Single Node (Dev):**
- $11/month
- No redundancy

**Multi-AZ Replica (Staging/Prod):**
- Automatic failover
- Extra cost (~50% more)
- Recommended for prod: $150/month

### Verdict: ‚úÖ **Redis is ESSENTIAL for performance**

---

## üîç Option 2: ElastiCache Memcached - ‚ö†Ô∏è **Simpler Alternative**

### What is Memcached?

Ultra-simple in-memory cache, key-value only.

### Differences from Redis:

| Feature | Redis | Memcached |
|---------|-------|-----------|
| Data Structures | Lists, Sets, Sorted Sets, Hashes | Key-Value only |
| Persistence | Optional RDB/AOF | None |
| TTL | Per-key | Global or per-key |
| Replication | Yes (cluster mode) | No |
| Transactions | Yes | No |

### When Memcached is Better:

‚úÖ Extremely simple use case  
‚úÖ No need for advanced structures  
‚úÖ Throwaway cache (OK to lose on restart)  

### Problems for Chatbot:

‚ùå Can't store complex session data (needs hashes/lists)  
‚ùå No persistence (lose cache on restart)  
‚ùå No replication (single point of failure)  

### Verdict: ‚ö†Ô∏è **Memcached is too simple for chatbot needs**

---

## üì§ Part 4: Messaging & Async Processing

### Problem: Why Messaging Needed?

**Without messaging:**
```
User sends message
    ‚Üì
API processes request
    ‚Üì
Save to MongoDB
    ‚Üì
Update analytics
    ‚Üì
Trigger model retraining
    ‚Üì
Send Slack notification
    ‚Üì
Wait for ALL to complete (5+ seconds)
    ‚Üì
Send response to user (slow!)
```

**With messaging:**
```
User sends message
    ‚Üì
API processes request
    ‚Üì
Save to MongoDB (quick)
    ‚Üì
Put "log_conversation" message in SQS
    ‚Üì
Put "update_analytics" message in SQS
    ‚Üì
Return response to user (fast! < 1 second)
    ‚Üì
(Background) Workers pick up SQS messages
    ‚Üì
(Background) Workers update analytics
    ‚Üì
(Background) Workers trigger retraining
```

---

## üîç Option 1: Amazon SQS - ‚úÖ **CHOSEN**

### What is SQS?

Simple queue service: producer puts messages, consumer picks them up.
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Backend   ‚îÇ (Producer)
‚îÇ API Service ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ Put message
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Amazon SQS         ‚îÇ
‚îÇ   (Message Queue)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ Poll message
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Worker Pods         ‚îÇ (Consumers)
‚îÇ  (Process messages)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Why SQS for Chatbot:

‚úÖ **Decouples Components**
- API doesn't wait for logging
- Workers independently scale

‚úÖ **Reliable Delivery**
- Messages retained for 14 days (default)
- Automatic retries
- Dead-letter queue for failures

‚úÖ **Async Processing**
```python
# Backend API
def chat_message(message):
    # Process quickly
    response = nlu.process(message)
    
    # Queue slow tasks
    sqs.send_message(
        QueueUrl='analytics-queue',
        MessageBody=json.dumps({
            'user_id': user_id,
            'intent': response.intent
        })
    )
    
    return response  # Return immediately!

# Worker (separate pods)
def process_analytics():
    while True:
        message = sqs.receive_messages(MaxNumberOfMessages=10)
        for msg in message:
            # Takes 2+ seconds, but doesn't block user
            update_analytics_database(msg.body)
            msg.delete()
```

‚úÖ **Cheap**
- $0.40 per million requests
- At 1,000 messages/day: $0.00012/month

‚úÖ **Auto-scaling**
- Workers scale based on queue depth
- If 10,000 messages pile up, scale workers to 100

### Use Cases in Chatbot:
```python
1. Conversation Logging
   - Save chat history asynchronously

2. Analytics Update
   - Track intent distribution
   - User behavior analysis

3. Model Retraining
   - Trigger weekly retraining
   - Don't block API

4. Notifications
   - Send Slack/email alerts
   - Don't wait for external services

5. Data Export
   - Export conversations for backup
   - Long-running task
```

### SQS Configuration

**Standard Queue (Recommended):**
- At-least-once delivery (might get duplicates)
- Unlimited throughput
- $0.40 per million requests

**FIFO Queue:**
- Exactly-once delivery
- 300 messages/second max
- $0.50 per million requests
- Useful for critical sequences

**For chatbot: Standard Queue is fine**
- Analytics duplicates don't hurt
- Throughput is unlimited

### Pricing

**At 1,000 messages/hour (24,000/day):**
- 720,000 messages/month
- Cost: 720,000 / 1,000,000 √ó $0.40 = $0.29/month

**Very cheap!**

### Verdict: ‚úÖ **SQS is IDEAL for async tasks**

---

## üîç Option 2: Amazon SNS (Pub/Sub) - ‚ö†Ô∏è **Supportive Role**

### What is SNS?

Publish-subscribe service: one message ‚Üí multiple subscribers.
```
Backend publishes event
    ‚Üì
SNS distributes to subscribers:
‚îú‚îÄ Email
‚îú‚îÄ Slack webhook
‚îú‚îÄ SQS queue
‚îî‚îÄ HTTP endpoint
```

### When SNS Works:

‚úÖ Broadcasting events to many targets  
‚úÖ Fan-out notifications  
‚úÖ Pub/sub patterns  

### For Chatbot:

**Limited use cases:**
- Alert ops team when error rate spikes
- Notify admins of model retraining completion
- Broadcast to multiple monitoring systems

**Not suitable as main messaging**

### Verdict: ‚ö†Ô∏è **SNS useful for notifications, not main messaging**

---

## üîç Option 3: Amazon EventBridge - ‚ö†Ô∏è **Over-Engineering**

### What is EventBridge?

Event bus with rule-based routing, schema validation, integrations.

### When EventBridge Works:

‚úÖ Many microservices  
‚úÖ Complex event workflows  
‚úÖ SaaS integrations  
‚úÖ Event schema validation  

### For Chatbot:

**Currently overkill:**
- Single backend service
- Simple event patterns
- No multi-service orchestration

**Future consideration:**
- If 5+ microservices: consider EventBridge
- Today: SQS is simpler

### Verdict: ‚ö†Ô∏è **EventBridge is over-engineering for current scope**

---

## üíæ Part 5: Object Storage

### Problem: Where to Store Non-Database Data?

**Data that doesn't fit in database:**
- Frontend static assets (HTML, CSS, JS)
- User-uploaded files
- Log files and exports
- Trained ML models
- Terraform state files
- Backup data

---

## üîç Option 1: Amazon S3 - ‚úÖ **CHOSEN**

### What is S3?

Object storage service: store any file in the cloud.
```
Frontend app ‚Üí CloudFront (CDN) ‚Üí S3 bucket
              (Caches files globally)
```

### Why S3 for Chatbot:

‚úÖ **Hosting Static Frontend**
```
1. Build Next.js app: npm run build
2. Deploy to S3 bucket
3. CloudFront caches globally
4. Users get instant load times
5. Cost: pennies/month
```

‚úÖ **Logs & Exports**
```python
# Export conversations
export_data = get_conversations()
s3.put_object(
    Bucket='chatbot-exports',
    Key=f'exports/{date}/conversations.json',
    Body=json.dumps(export_data)
)
```

‚úÖ **ML Artifacts**
- Trained models stored in S3
- Workers download models from S3
- New versions deployed without container rebuild

‚úÖ **Backup Storage**
- Daily backups of MongoDB exported to S3
- 11 nines durability
- Lifecycle policies move old files to Glacier

‚úÖ **Terraform State**
- terraform.tfstate stored in S3
- Lock file in DynamoDB
- Team collaboration on infrastructure

### S3 Pricing

**At 10GB of data:**
- Storage: 10GB √ó $0.023/GB = $0.23/month
- GET requests: minimal cost
- **Total: < $1/month**

**With CloudFront (frontend delivery):**
- CloudFront egress: $0.085/GB
- For 1TB/month traffic: $85/month
- With caching, typical: 10-20% hit, so $8-16/month

### S3 Best Practices
```python
# 1. Versioning enabled (safe rollback)
s3.put_bucket_versioning(Bucket='chatbot-exports', VersioningConfiguration={'Status': 'Enabled'})

# 2. Lifecycle policies (cost optimization)
# Move old exports to Glacier after 90 days
# Delete after 2 years

# 3. Server-side encryption
s3.put_object(
    Bucket='chatbot-exports',
    Key='data.json',
    ServerSideEncryption='AES256'
)

# 4. Public access blocked (security)
s3.put_public_access_block(
    Bucket='chatbot-exports',
    PublicAccessBlockConfiguration={
        'BlockPublicAcls': True,
        'BlockPublicPolicy': True,
        'IgnorePublicAcls': True,
        'RestrictPublicBuckets': True
    }
)
```

### Verdict: ‚úÖ **S3 is essential, universal choice**

---

## üîç Option 2: Amazon EBS - ‚ùå **NOT Suitable**

### What is EBS?

Block storage attached to EC2 instances (like a hard drive).

### When EBS Works:

‚úÖ OS disks for servers  
‚úÖ Database volumes  
‚úÖ Single-instance persistent storage  

### For Chatbot:

‚ùå **Data is bound to one server**
- If EC2 dies, data is lost (unless snapshot)
- Can't be shared across pods

‚ùå **Stuck to EKS nodes**
- Pods run in different nodes
- Can't migrate pod to different node

‚ùå **Wrong abstraction**
- Chatbot data is ephemeral
- Backend pods are stateless (state in MongoDB/Redis)

### Verdict: ‚ùå **EBS is not suitable**

---

## üîç Option 3: Amazon EFS - ‚ö†Ô∏è **Overcomplicated**

### What is EFS?

Shared network file system (like NFS).

### When EFS Works:

‚úÖ Multiple instances sharing files  
‚úÖ Stateful workloads  
‚úÖ Legacy apps needing shared storage  

### For Chatbot:

‚ùå **App is already stateless**
- MongoDB holds state
- Redis caches state
- No need for shared file system

‚ùå **More expensive than S3**
- EFS: $0.30/GB/month
- S3: $0.023/GB/month
- 13x more expensive!

### Verdict: ‚ö†Ô∏è **EFS is overkill for chatbot**

---

## üìä Final Architecture Summary Table

| Component | Service | Cost/Month | Justification |
|-----------|---------|-----------|---------------|
| **Compute** | EKS | $73 + $100 | Long-running APIs, ML isolation, Helm + GitOps |
| **Database** | MongoDB Atlas M10 | $57 √ó 3 = $171 | Document model, existing code, flexible schema |
| **Caching** | ElastiCache Redis | ~$130 | Session storage, conversation context, performance |
| **Messaging** | SQS | < $1 | Async processing, decoupling, cheap |
| **Storage** | S3 | < $5 | Static frontend, logs, models, Terraform state |
| **Frontend CDN** | CloudFront | $10-20 | Global distribution, caching |
| **ECR** | Container Registry | < $1 | Docker image storage |
| **Monitoring** | CloudWatch | $10-20 | Logs, metrics, alarms |
| **TOTAL/MONTH** | | **$560** | All 3 environments (dev, staging, prod) |

---

## üéì Key Takeaways

### Compute
- **EKS** beats Lambda/AppRunner/ECS because:
  - Long-running stateful APIs need it
  - ML workloads need fine-grained resource control
  - Industry standard with Helm + GitOps integration

### Database
- **MongoDB Atlas** beats RDS/DynamoDB because:
  - Existing codebase uses MongoDB
  - Document model fits conversation data
  - Schema flexibility for evolving NLU

### Cache
- **Redis** beats Memcached because:
  - Advanced structures for complex state
  - Replication for HA
  - TTL for sessions

### Messaging
- **SQS** beats SNS/EventBridge because:
  - Simple queue for async tasks
  - Cheap
  - Workers scale independently

### Storage
- **S3** is universal because:
  - Cheap
  - Durable
  - Perfect for static assets, logs, models

---

## ‚úÖ Final Conclusion

**The selected architecture balances operational simplicity, scalability, and cost efficiency while aligning with the existing codebase and supporting future growth of the AI chatbot platform.**

Total estimated cost: **$560/month** for 3 production-grade environments

Next: See [AWS Account Structure](02-AWS-ACCOUNT-STRUCTURE.md) for security and multi-account design.

